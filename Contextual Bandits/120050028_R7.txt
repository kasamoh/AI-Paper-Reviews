Rohit Kumar
120050028

Primary reference : A Contextual-Bandit Approach to Personalized News Article Recommendation; Lihong Li, Wei Chu, John Langford, Robert E. Schapire

The paper describes a contextual bandit algorithm to provide personalized news article recommendation. This problem is challenging because the content pool is dynamically changing and for practical interests, only those solutions would work which are fast in learning and computation. The article selecting strategy is based on user-click feedback and the aim of the algorithm is to maximize user clicks. Results obtained by this algorithm showed a 12.5% increase in clicks compared to a standard context-free bandit algorithm, and the advantage is claimed to be even greater in case when data is scarce.

Related work include exploitation-exploration approaches based on users' response. Users and contents are represented as features. They provide meaningful recommendations by leveraging user interests as demonstrated by their past activity and by recognizing similarities across users based on their consumption history. But in a lot of web-based scenarios, the content universe changes frequently and a lot of users are entirely new with no historic consumption which makes traditional recommendation systems difficult to apply.

It is crucial to learn the match/relation between user interest and content when one or both of them are new, but acquiring such information can reduce user satisfaction. So the problem boils down to optimally balance between maximizing user satisfaction in the long run and learn about relation between user interest and content.

The paper describes a new algorithm called LinUCB which is similar to UCB and is a generic contextual bandit problem. In this algorithm, confidence interval is shown to be computed efficiently in closed form, when the payoff model is linear. The paper first describes a simpler version of this algorithm for disjoint linear models. In this case, the input parameters (contexts for articles, user clicks) are not shared among different arms. A design matrix is used to capture the observed context for a given article. The coefficients of the feature of an arm is calculated by applying ridge regression using this design matrix and user clicks as data points. A suitable confidence bound is calculated and the arm which maximizes the value corresponding to the current expected reward and the confidence bound is chosen for sampling.

In case of hybrid models, the features can be shared across arms. Formally, a coefficient vector which is common to all the arms is used apart from the arm specific coefficient vector. This common vector captures the feature of the current user-article combination. Block matrix inversion techniques are used to solve this UCB.

Real world experiments are shown to provide comparison with standard contextual bandit algorithms. They have experimented with the Yahoo! Today Module, which is a prominent panel on the Yahoo front page. The performance metric used is CTR, which is ratio of ratio of no of clicks received and the no of steps it run. Based on real Yahoo! Front Page traffic, the paper claims that upper confidence bound methods generally outperform the simpler but unguided epsilon-greedy methods. The algorithm LinUCB shows advantages when data are sparse, suggesting its effectiveness to personalized web services when the number of contents in the pool is large.

Overall the paper provides a good breakthrough in the recommendation domain. I found the mathematical part and the pseudo code a bit hard to follow, especially the hybrid model one. Future works may include investigation on other web based services such as online advertisement. Also, since user interests evolve over time, it is important to consider those changes also.
